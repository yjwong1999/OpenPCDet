{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenPCDet**\n",
        "\n",
        "**Author:** [Yi-Jie Wong](https://www.linkedin.com/in/wongyijie/) & [Wingates Voon](https://www.linkedin.com/in/wingates-voon-5858391a0/) & [Yan-Chai Hum](https://www2.utar.edu.my/cv/index.jsp?cv=humyc&reqPageId=aboutMe)<br>\n",
        "**GitHub:** [OpenPCDet](https://github.com/yjwong1999/OpenPCDet.git)<br>\n",
        "**Date created:** 2023/05/07<br>\n",
        "**Last modified:** 2023/11/27<br>\n",
        "**Description:** Training 3D Object Detection Models using a highly specialized OpenPCDet-based pipeline\n",
        "\n",
        "Pipeline Definition\n",
        "1.   **Preprocessing** (standard: downsampling + removal of outlier point clouds)\n",
        "2.   **Custon Preprocessing** (splitting point clouds into 2 + cropping ROI)\n",
        "3.   **Annotation** (using LabelCLoud, which is a Python based tool)\n",
        "4.   **Automated Augmentation** (an augmentation pipeline we devised for the project)\n",
        "5.   **Convert raw data to OpenPCDet format** (necessary conversion)\n",
        "6.   **OpenPCDet's own processing** (which is included in Part 7./8.)\n",
        "7.   **OpenPCDet training**\n",
        "8.   **OpenPCDet deployment**"
      ],
      "metadata": {
        "id": "cSahTlSko06k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get ready the environment and dependencies"
      ],
      "metadata": {
        "id": "f62vmoDXo9Ep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2kZ6aJjniRr"
      },
      "outputs": [],
      "source": [
        "# check CUDA version (11.8 in this case)\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check torch cuda version, make sure same as the version provided by nvcc\n",
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "4noYvPDwpwx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install the spconv with the same version as pytorch and nvcc\n",
        "# for this case, we need to install spconv for cuda 11.8 version\n",
        "# hence, install spconv-cu118\n",
        "!pip install spconv-cu118"
      ],
      "metadata": {
        "id": "1xV0hebqpynS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup OpenPCDet\n",
        "!git clone https://github.com/yjwong1999/OpenPCDet.git"
      ],
      "metadata": {
        "id": "9uxJ8xEup0mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd OpenPCDet"
      ],
      "metadata": {
        "id": "RLhbPPegqa_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this will authomatically setup the OpenPCDet\n",
        "!python setup.py develop"
      ],
      "metadata": {
        "id": "BAY28D2_qeEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install remaining dependencies following the version specified\n",
        "\n",
        "from IPython.display import clear_output\n",
        "# !pip install pandas==1.5.3\n",
        "!pip install plyfile==1.0.1\n",
        "# !pip install opencv-python==4.7.0.72\n",
        "!pip install av2==0.2.1\n",
        "!pip install kornia==0.5.8\n",
        "!pip install mayavi==4.8.1\n",
        "!pip install PyQt5==5.15.9\n",
        "!pip install open3d==0.17.0\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "IBvJaYgVqhLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data (follow Option 2 for simplicity's sake)"
      ],
      "metadata": {
        "id": "W0DK_5ZZz1zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Process data from top to bottom (data & label collection -> preprocessing -> augmentation -> conversion to OpenPCDet format)\n",
        "# This .sh file will do Step 1 to Step 5\n",
        "# Step 1: Preprocessing (standard: downsampling + removal of outlier point clouds)\n",
        "# Step 2: Custom Preprocessing (splitting point clouds into 2 + cropping ROI)\n",
        "# Step 3: Annotation using LabelCLoud (for simplicity sake, we assumed this is ready)\n",
        "# Step 4: Automated Augmentation (an augmentation pipeline we devised for the project)\n",
        "# Step 5: Convert raw data to OpenPCDet format (necessary conversion)\n",
        "\n",
        "# !bash bash_data.sh"
      ],
      "metadata": {
        "id": "Q7e8WHOf32qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2: To start after augmentation (conversion to OpenPCDet format))\n",
        "\n",
        "!bash bash_ready_data.sh"
      ],
      "metadata": {
        "id": "LGtqRP2n5eOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Training"
      ],
      "metadata": {
        "id": "-kqeXfPtYmru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Train PointPillar via conventional method\n",
        "# Step 6. OpenPCDet's own processing (which is included in Part 7./8.)\n",
        "# Step 7. OpenPCDet training\n",
        "\n",
        "!bash bash_train.sh"
      ],
      "metadata": {
        "id": "i5ed9h8i32oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2: Train PointPillar via reptile method\n",
        "# Step 6. OpenPCDet's own processing (which is included in Part 7./8.)\n",
        "# Step 7. OpenPCDet training via Reptile\n",
        "\n",
        "# Disclaimer\n",
        "# Please note that, we cant finish the reptile training in Colab due to limited runtime\n",
        "# Hence, we only use 10 epochs for each training (we used 100 epochs for actual training)\n",
        "\n",
        "!bash bash_reptile.sh"
      ],
      "metadata": {
        "id": "zxlosY_S9Oy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test (evaluation)"
      ],
      "metadata": {
        "id": "F9vVJlusY2rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tools\n",
        "!python test.py \\\n",
        "    --cfg_file cfgs/custom_models/pointpillar.yaml \\\n",
        "    --ckpt ../output/custom_models/pointpillar/default/ckpt/checkpoint_epoch_100.pth \\\n",
        "    --infer_time\n",
        "    #--data_path \"../data/custom/points\" --ext .npy\n",
        "%cd ../"
      ],
      "metadata": {
        "id": "X7234dHy5iWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo"
      ],
      "metadata": {
        "id": "HcL9h96tY5dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash bash_demo.sh"
      ],
      "metadata": {
        "id": "Xrv4cSha9OIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}